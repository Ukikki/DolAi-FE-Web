import { useRef } from "react";
import axios from "@/utils/axiosInstance";

declare global {
  interface Window {
    ImageCapture: any;
  }
}

declare class ImageCapture {
  constructor(videoTrack: MediaStreamTrack);
  grabFrame(): Promise<ImageBitmap>;
}

const flattenOcrText = (ocrData: any): string => {
  try {
    return ocrData?.regions
      ?.flatMap((region: any) =>
        region.lines?.flatMap((line: any) =>
          line.words?.map((w: any) => w.text)
        )
      )
      .filter(Boolean)
      .join(" ") || "";
  } catch {
    return "";
  }
};

export const useScreenShare = (meetingId: string, userId: string) => {
  const displayStreamRef = useRef<MediaStream | null>(null);
  const ocrIntervalRef = useRef<number | null>(null);

  const screenShareStart = async () => {
    try {
      const statusRes = await axios.get(`/meetings/${meetingId}/screen-share/status`);
      if (statusRes.data?.active) {
        alert("ì´ë¯¸ í™”ë©´ ê³µìœ  ì¤‘ì…ë‹ˆë‹¤.");
        return;
      }

      const displayStream = await navigator.mediaDevices.getDisplayMedia({ video: true });
      displayStreamRef.current = displayStream;

      const track = displayStream.getVideoTracks()[0];

      // âœ… íŠ¸ë™ ì¢…ë£Œ ì´ë²¤íŠ¸ â†’ OCR ë¨¼ì € ì‹¤í–‰ â†’ ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ
      track.onended = async () => {
        console.log("ğŸ›‘ í™”ë©´ ê³µìœ  ì‚¬ìš©ì ì¢…ë£Œë¨");
        await runFinalOcrAndSend(); // OCR ë¨¼ì €
        await stopStreamOnly();     // ìŠ¤íŠ¸ë¦¼ ì •ë¦¬
      };

      await axios.post(`/meetings/${meetingId}/screen-share/start`, { userId });
      console.log("âœ… í™”ë©´ ê³µìœ  ì‹œì‘");

      startOcrInterval(); // OCR ìë™ ì‹œì‘

    } catch (err) {
      console.error("âŒ í™”ë©´ ê³µìœ  ì‹œì‘ ì‹¤íŒ¨:", err);
    }
  };

  const screenShareStop = async () => {
    await runFinalOcrAndSend(); // OCR ë¨¼ì € í•˜ê³ 
    await stopStreamOnly();     // ê·¸ ë‹¤ìŒ ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ
  };

  const stopStreamOnly = async () => {
    try {
      displayStreamRef.current?.getTracks().forEach((t) => t.stop());
      displayStreamRef.current = null;

      if (ocrIntervalRef.current) {
        clearInterval(ocrIntervalRef.current);
        ocrIntervalRef.current = null;
      }

      console.log("ğŸ§¼ í™”ë©´ ê³µìœ  ì •ë¦¬ ì™„ë£Œ");

    } catch (err) {
      console.error("âŒ ìŠ¤íŠ¸ë¦¼ ì •ë¦¬ ì‹¤íŒ¨:", err);
    }
  };

  const runFinalOcrAndSend = async () => {
    try {
      const result = await captureAndSendOcr();
      const ocrText = flattenOcrText(result);
      const timestamp = new Date().toISOString();

      await axios.post(`/meetings/${meetingId}/screen-share/stop`, {
        userId,
        text: ocrText,
        timestamp,
      });

      console.log("âœ… OCR ìµœì¢… ì €ì¥ ì™„ë£Œ");

    } catch (err) {
      console.warn("âš ï¸ ë§ˆì§€ë§‰ OCR ì‹¤íŒ¨, ìƒëµí•¨", err);
    }
  };

  const captureAndSendOcr = async (): Promise<any> => {
    const stream = displayStreamRef.current;
    if (!stream) throw new Error("í™”ë©´ ê³µìœ  ì¤‘ì´ ì•„ë‹™ë‹ˆë‹¤.");

    const track = stream.getVideoTracks()[0];
    const imageCapture = new ImageCapture(track);
    const bitmap = await imageCapture.grabFrame();

    const canvas = document.createElement("canvas");
    canvas.width = bitmap.width;
    canvas.height = bitmap.height;

    const ctx = canvas.getContext("2d");
    if (!ctx) throw new Error("Canvas 2D context ì˜¤ë¥˜");

    ctx.drawImage(bitmap, 0, 0);
    const blob = await new Promise<Blob>((resolve) =>
      canvas.toBlob((b) => {
        if (b) {
          console.log("ğŸ–¼ï¸ blob ìƒì„± ì™„ë£Œ, í¬ê¸°:", b.size, "bytes");
          resolve(b);
        } else {
          throw new Error("âŒ canvas â†’ blob ë³€í™˜ ì‹¤íŒ¨");
        }
      }, "image/png")
    );    

    const formData = new FormData();
    formData.append("file", blob, "capture.png");

    const response = await axios.post("/azure-ocr/image", formData, {
      headers: { "Content-Type": "multipart/form-data" },
    });

    console.log("ğŸ“„ OCR ìº¡ì²˜ ê²°ê³¼:", response.data);
    return response.data;
  };

  const startOcrInterval = () => {
    ocrIntervalRef.current = window.setInterval(async () => {
      try {
        const result = await captureAndSendOcr();
        console.log("ğŸ“„ OCR ìë™ ê²°ê³¼:", result);
      } catch (err) {
        console.warn("âš ï¸ OCR ìë™ ìº¡ì²˜ ì‹¤íŒ¨:", err);
      }
    }, 10000); // 10ì´ˆ ê°„ê²©
  };

  return {
    screenShareStart,
    screenShareStop,
    isSharing: !!displayStreamRef.current,
  };
};
